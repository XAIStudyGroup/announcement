## Welcome to the Explainable AI Study Group at iSchool, UIUC

Explainable AI study group aims to create a low-pressure, peer-mentoring learning space for students to learn and practice explainable AI (XAI) techniques. For each session, one instructor will walk the audience through a working example of an explainable AI method. Unlike conventional reading groups, this group emphasizes hands-on learning. And learners do not need to prepare before the sessions. We will "open our doors" in **Spring 2022**. You are welcome to "watch" this repository for any updates.

## Sessions
- [Yuanxi Fu](https://ischool.illinois.edu/people/yuanxi-fu): Overview of Interpretability (Jan 29, 2022) [**Registration**](https://illinois.zoom.us/meeting/register/tZcvdO2orT0pEtcaJjnNYbVH8oamISt4gCVR)
- [Malik Salami](https://ischool.illinois.edu/people/malik-salami): Explain Linear Regression Model and [Yuanxi Fu](https://ischool.illinois.edu/people/yuanxi-fu): Explain Logistic Regression Model (Feb 12, 2022) [**Registration**](https://illinois.zoom.us/meeting/register/tZ0oceirrzkjE9Bih4Cye6H1KvWVhbNUFIZk)
- TBD: Explain Decision Tree Model (Feb 26, 2022) [**Registration**](https://illinois.zoom.us/meeting/register/tZMkdO-rpjIoGtP6ju6PSOp7DRLmgQbtkxST)
- One more advanced XAI technique (TBD)(Mar 5, 2022 or TBD after the spring break)

## Prerequisite  
To attend our sessions, you only need to have two types of IDEs (Integrated programming environment) installed on your computer and know how to use them. One for R and one for Python, since we allow instructors to choose which language they want to code their examples in. No prior experience in ML is needed, but having it is a plus.

## Instructors  
Since this is a peer-mentoring learning space, we do not hold instructors to the same high standard for a real classroom. You have two options on how to lead your session.  
1. Demonstrate the method: You can choose a method, code a working example of using this method to explain your machine learning or deep learning model, and show how you do it to the audience. This one takes less effort.
2. Explain your model: Pretend the audience is a group a stakeholders. They are eager to know more about the cool model you have built. You will prepare a presentation to explain the model. This is the harder option, but you will gain the valuable experience of actually "explaining" your model.

**Why there are two options?** Interpretations does not immediate lend to human-understandable explanations. I added the second option so that some of us can actually practice "explanation" and understand its pitfalls. 

We welcome any upper-level undergraduate students, master's students, and PhD students to try on the role of instructors. Develop your code on your own and let me know when the repository is ready to be forked.  

## Contact us about questions  
Open an issue in this repository, so we will see it. 

## Q&A

